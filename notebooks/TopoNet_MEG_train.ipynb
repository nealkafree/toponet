{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Notebook for training TopoNEt model on MEG data for predicting the task being performed\n",
    "\n",
    "Model architecture - https://arxiv.org/pdf/1611.08024\n",
    "\n",
    "Training data - MEG data recorder while people were performing different tasks."
   ],
   "id": "98adf53937fc6da2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T05:50:21.974969Z",
     "start_time": "2025-06-02T05:50:21.972293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from pymatreader import read_mat\n",
    "import numpy as np"
   ],
   "id": "86a764081524d43f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## First experiment\n",
    "0.5 seconds before the actual experiment has started. Participant is informed, what he needs to pay attention to.\n",
    "Only one participant is used for training and testing."
   ],
   "id": "e67a0e44b2acc9e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Loading data",
   "id": "d65b64d21179788f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T05:50:22.048254Z",
     "start_time": "2025-06-02T05:50:22.044999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_first_500ms(file_path: str) -> list:\n",
    "    \"\"\"\n",
    "    Loads trials from a file and takes the first 500ms of data from them.\n",
    "    :return: (500ms_of_trial, label) where label indicates what subject was attenting to.\n",
    "    \"\"\"\n",
    "    label = file_path.split('_')[-2]\n",
    "\n",
    "    data = read_mat(file_path)\n",
    "    cut_data = []\n",
    "    for trial in data['finalStruct']['trial']:\n",
    "        cut_trial = np.empty([0, 500])\n",
    "        for sensor in trial:\n",
    "            cut_trial = np.append(cut_trial, sensor[:500])\n",
    "        cut_data.append((cut_trial, label))\n",
    "    return cut_data"
   ],
   "id": "22e155c8b0549baa",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T05:52:23.281489Z",
     "start_time": "2025-06-02T05:52:03.665650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SUBJECT_NUMBER = '01' # We can train our models on different participants\n",
    "\n",
    "data = load_first_500ms(f'/mnt/diska/baldauf/Subject_{SUBJECT_NUMBER}_OnsetStim_BOT_scoutTimeSeriesNew.mat') + \\\n",
    "    load_first_500ms(f'/mnt/diska/baldauf/Subject_{SUBJECT_NUMBER}_OnsetStim_TOP_scoutTimeSeriesNew.mat')\n",
    "\n",
    "# Since we have a small amount of data, we will only use traint and test\n",
    "test_size = int(0.1 * len(data))\n",
    "train_dataset, test_dataset = random_split(data, [len(data) - test_size, test_size])\n",
    "\n",
    "torch.manual_seed(42) # for reproducibility\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "len(data) - test_size"
   ],
   "id": "356e802ccd36ee1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model classes\n",
    "\n",
    "Here we implement EEGNet, but with some modifications, due to the nature of our data and need to use topographical constraints."
   ],
   "id": "e714dbc84c538907"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ConstrainedConv2d(nn.Conv2d):\n",
    "    \"\"\"\n",
    "    Implementation of maximum norm constraint for Conv2D layer\n",
    "    \"\"\"\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return F.conv2d(x, self.weight.clamp(max=1.0), self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "class ConstrainedLinear(nn.Linear):\n",
    "    \"\"\"\n",
    "    Implementation of maximum norm constraint for Linear layer\n",
    "    \"\"\"\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return F.linear(x, self.weight.clamp(max=0.5), self.bias)\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, sensors: int, samples: int, num_classes: int, f1: int, depth: int, f2: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            # Since we have only 500ms of data we set kernel length at 250\n",
    "            # So we can capture patterns with frequency above 4Hz\n",
    "            nn.Conv2d(in_channels=1, out_channels=f1, kernel_size=(1, 250), padding='same',\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(f1),\n",
    "            ConstrainedConv2d(in_channels=f1, out_channels=f1*depth, kernel_size=(sensors, 1), padding='same',\n",
    "                      groups=f1, bias=False),\n",
    "            nn.BatchNorm2d(f1*depth),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, 4)),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=f1*depth, out_channels=f1*depth, kernel_size=(1, 16), padding='same',\n",
    "                      groups=f1*depth, bias=False),\n",
    "            nn.Conv2d(in_channels=f1*depth, out_channels=f2, kernel_size=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(f2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, 8)),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        # We have to add one dense layer in order to implement topographical constraints\n",
    "        self.linear = ConstrainedLinear(in_features=f2*samples//32, out_features=36)\n",
    "        self.classifier = nn.Linear(in_features=36, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.linear(x)\n",
    "        return self.classifier(x)\n"
   ],
   "id": "eba37aa8f0bfd12a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-topography-env]",
   "language": "python",
   "name": "conda-env-.conda-topography-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
